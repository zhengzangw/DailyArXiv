---
title: Latest 15 Papers - January 16, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering](https://arxiv.org/abs/2601.09697v1)** | 2026-01-14 | <details><summary>Proje...</summary><p>Project page: https://ayushtewari.com/projects/srender/</p></details> |
| **[Physically Plausible Multi-System Trajectory Generation and Symmetry Discovery](https://arxiv.org/abs/2509.23003v2)** | 2026-01-14 |  |
| **[VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction](https://arxiv.org/abs/2601.05966v2)** | 2026-01-14 | <details><summary>Proje...</summary><p>Project page: https://ernie-research.github.io/VideoAR/</p></details> |
| **[PhyRPR: Training-Free Physics-Constrained Video Generation](https://arxiv.org/abs/2601.09255v1)** | 2026-01-14 |  |
| **[JoyAvatar-Flash: Real-time and Infinite Audio-Driven Avatar Generation with Autoregressive Diffusion](https://arxiv.org/abs/2512.11423v2)** | 2026-01-14 |  |
| **[Beyond the Last Frame: Process-aware Evaluation for Generative Video Reasoning](https://arxiv.org/abs/2512.24952v2)** | 2026-01-14 | Work in progress |
| **[MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head](https://arxiv.org/abs/2601.07832v2)** | 2026-01-14 | <details><summary>Code:...</summary><p>Code: https://github.com/DAGroup-PKU/MHLA/ Project website: https://dagroup-pku.github.io/MHLA/</p></details> |
| **[DyDiT++: Diffusion Transformers with Timestep and Spatial Dynamics for Efficient Visual Generation](https://arxiv.org/abs/2504.06803v4)** | 2026-01-14 | <details><summary>This ...</summary><p>This paper was accepted to the IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) on January 9, 2026. arXiv admin note: substantial text overlap with arXiv:2410.03456</p></details> |
| **[Motion Attribution for Video Generation](https://arxiv.org/abs/2601.08828v1)** | 2026-01-13 | <details><summary>See t...</summary><p>See the project website at https://research.nvidia.com/labs/sil/projects/MOTIVE/</p></details> |
| **[DGAE: Diffusion-Guided Autoencoder for Efficient Latent Representation Learning](https://arxiv.org/abs/2506.09644v2)** | 2026-01-13 |  |
| **[Simulating the Visual World with Artificial Intelligence: A Roadmap](https://arxiv.org/abs/2511.08585v2)** | 2026-01-13 | <details><summary>Proje...</summary><p>Project page: https://world-model-roadmap.github.io/ Github Repo: https://github.com/ziqihuangg/Awesome-From-Video-Generation-to-World-Model</p></details> |
| **[Video Generation Models in Robotics -- Applications, Research Challenges, Future Directions](https://arxiv.org/abs/2601.07823v1)** | 2026-01-12 |  |
| **[Forecast the Principal, Stabilize the Residual: Subspace-Aware Feature Caching for Efficient Diffusion Transformers](https://arxiv.org/abs/2601.07396v1)** | 2026-01-12 |  |
| **[Perception Test 2025: Challenge Summary and a Unified VQA Extension](https://arxiv.org/abs/2601.06287v1)** | 2026-01-09 |  |
| **[Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals](https://arxiv.org/abs/2601.05848v1)** | 2026-01-09 | <details><summary>Code ...</summary><p>Code and interactive demos at https://goal-force.github.io/</p></details> |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering](https://arxiv.org/abs/2601.09697v1)** | 2026-01-14 | <details><summary>Proje...</summary><p>Project page: https://ayushtewari.com/projects/srender/</p></details> |
| **[Coupled Data and Measurement Space Dynamics for Enhanced Diffusion Posterior Sampling](https://arxiv.org/abs/2510.09676v2)** | 2026-01-14 |  |
| **[Can AI Dream of Unseen Galaxies? Conditional Diffusion Model for Galaxy Morphology Augmentation](https://arxiv.org/abs/2506.16233v2)** | 2026-01-14 | <details><summary>29 pa...</summary><p>29 pages, 17 figures, accepted version for ApJS. Comments welcome. See another independent work for further reference, Category-based Galaxy Image Generation via Diffusion Models (Fan, Tang et al.)</p></details> |
| **[Trustworthy Longitudinal Brain MRI Completion: A Deformation-Based Approach with KAN-Enhanced Diffusion Model](https://arxiv.org/abs/2601.09572v1)** | 2026-01-14 |  |
| **[ViSTA: Visual Storytelling using Multi-modal Adapters for Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.12198v2)** | 2026-01-14 | <details><summary>Accep...</summary><p>Accepted to WACV 2026</p></details> |
| **[Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts](https://arxiv.org/abs/2309.06135v3)** | 2026-01-14 | <details><summary>ICML ...</summary><p>ICML 2024 main conference paper. The source code is available at https://github.com/zhiyichin/P4D</p></details> |
| **[Diffusion-Aided Bandwidth-Efficient Semantic Communication with Adaptive Requests](https://arxiv.org/abs/2510.26442v3)** | 2026-01-14 |  |
| **[FeatInv: Spatially resolved mapping from feature space to input space using conditional diffusion models](https://arxiv.org/abs/2505.21032v2)** | 2026-01-14 | <details><summary>Versi...</summary><p>Version published by Transactions on Machine Learning Research in 2025 (TMLR ISSN 2835-8856) at https://openreview.net/forum?id=UtE1YnPNgZ. 32 pages, 27 figures. This work builds on an earlier manuscript (arXiv:2505.21032) and crucially extends it. Code is available at https://github.com/AI4HealthUOL/FeatInv</p></details> |
| **[Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models](https://arxiv.org/abs/2506.17139v3)** | 2026-01-14 | <details><summary>Accep...</summary><p>Accepted at Conference on Neural Information Processing Systems (NeurIPS 2025)</p></details> |
| **[Research on Piano Timbre Transformation System Based on Diffusion Model](https://arxiv.org/abs/2601.09333v1)** | 2026-01-14 |  |
| **[Controlling Ensemble Variance in Diffusion Models: An Application for Reanalyses Downscaling](https://arxiv.org/abs/2501.14822v2)** | 2026-01-14 |  |
| **[IKDiffuser: a Diffusion-based Generative Inverse Kinematics Solver for Kinematic Trees](https://arxiv.org/abs/2506.13087v4)** | 2026-01-14 | under review |
| **[Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative Decoding](https://arxiv.org/abs/2509.18085v3)** | 2026-01-14 | <details><summary>Origi...</summary><p>Original version uploaded on Sep 22, 2025. (v2): Extended Table 2 with additional analysis and referenced it in Sec 5.2. (v3): Added note to Sec 4.2 and Appendix A.2 specifying conditions for losslessness</p></details> |
| **[JoyAvatar-Flash: Real-time and Infinite Audio-Driven Avatar Generation with Autoregressive Diffusion](https://arxiv.org/abs/2512.11423v2)** | 2026-01-14 |  |
| **[SpikeVAEDiff: Neural Spike-based Natural Visual Scene Reconstruction via VD-VAE and Versatile Diffusion](https://arxiv.org/abs/2601.09213v1)** | 2026-01-14 | Preprint |

