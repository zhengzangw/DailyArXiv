---
title: Latest 15 Papers - May 26, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Motion by Queries: Identity-Motion Trade-offs in Text-to-Video Generation](http://arxiv.org/abs/2412.07750v3)** | 2025-05-22 | <details><summary>(1) P...</summary><p>(1) Project page: https://research.nvidia.com/labs/par/MotionByQueries/ (2) The methods and results in section 5, "Consistent multi-shot video generation", are based on the arXiv version 1 (v1) of this work. Starting version 2 (v2), we extend and further analyze those findings to efficient motion transfer (3) in v3 we added: results with WAN 2.1, baselines and more quality metrics</p></details> |
| **[Training-Free Efficient Video Generation via Dynamic Token Carving](http://arxiv.org/abs/2505.16864v1)** | 2025-05-22 | <details><summary>Proje...</summary><p>Project Page: https://julianjuaner.github.io/projects/jenga/ , 24 pages</p></details> |
| **[Action2Dialogue: Generating Character-Centric Narratives from Scene-Level Prompts](http://arxiv.org/abs/2505.16819v1)** | 2025-05-22 | 18 pages, 5 figures |
| **[MAGIC: Motion-Aware Generative Inference via Confidence-Guided LLM](http://arxiv.org/abs/2505.16456v1)** | 2025-05-22 |  |
| **[AniSora: Exploring the Frontiers of Animation Video Generation in the Sora Era](http://arxiv.org/abs/2412.10255v5)** | 2025-05-22 |  |
| **[Generative Pre-trained Autoregressive Diffusion Transformer](http://arxiv.org/abs/2505.07344v4)** | 2025-05-22 |  |
| **[Challenger: Affordable Adversarial Driving Video Generation](http://arxiv.org/abs/2505.15880v1)** | 2025-05-21 | <details><summary>Proje...</summary><p>Project page: https://pixtella.github.io/Challenger/</p></details> |
| **[Interspatial Attention for Efficient 4D Human Video Generation](http://arxiv.org/abs/2505.15800v1)** | 2025-05-21 | <details><summary>Proje...</summary><p>Project page: https://dsaurus.github.io/isa4d/</p></details> |
| **[Ca2-VDM: Efficient Autoregressive Video Diffusion Model with Causal Generation and Cache Sharing](http://arxiv.org/abs/2411.16375v2)** | 2025-05-21 | <details><summary>Accep...</summary><p>Accepted by ICML 2025. Code is available: https://github.com/Dawn-LX/CausalCache-VDM</p></details> |
| **[BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation](http://arxiv.org/abs/2505.12620v2)** | 2025-05-21 |  |
| **[LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities](http://arxiv.org/abs/2502.12128v3)** | 2025-05-21 | <details><summary>Proje...</summary><p>Project page: https://ml-jku.github.io/LaM-SLidE/</p></details> |
| **[Generative AI for Autonomous Driving: A Review](http://arxiv.org/abs/2505.15863v1)** | 2025-05-21 | <details><summary>This ...</summary><p>This work has been submitted to the IEEE for possible publication</p></details> |
| **[AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection](http://arxiv.org/abs/2505.15173v1)** | 2025-05-21 |  |
| **[CineTechBench: A Benchmark for Cinematographic Technique Understanding and Generation](http://arxiv.org/abs/2505.15145v1)** | 2025-05-21 | Under review |
| **[AnyCharV: Bootstrap Controllable Character Video Generation with Fine-to-Coarse Guidance](http://arxiv.org/abs/2502.08189v2)** | 2025-05-21 | <details><summary>18 pa...</summary><p>18 pages, 10 figures, 4 tables</p></details> |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[When Are Concepts Erased From Diffusion Models?](http://arxiv.org/abs/2505.17013v1)** | 2025-05-22 | <details><summary>Proje...</summary><p>Project Page: https://nyu-dice-lab.github.io/when-are-concepts-erased/</p></details> |
| **[Guided Diffusion Sampling on Function Spaces with Applications to PDEs](http://arxiv.org/abs/2505.17004v1)** | 2025-05-22 |  |
| **[Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding](http://arxiv.org/abs/2505.16990v1)** | 2025-05-22 |  |
| **[Incorporating Visual Correspondence into Diffusion Model for Virtual Try-On](http://arxiv.org/abs/2505.16977v1)** | 2025-05-22 | <details><summary>ICLR ...</summary><p>ICLR 2025. Code is publicly available at: https://github.com/HiDream-ai/SPM-Diff</p></details> |
| **[Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models](http://arxiv.org/abs/2505.16959v1)** | 2025-05-22 |  |
| **[Statistical guarantees for denoising reflected diffusion models](http://arxiv.org/abs/2411.01563v2)** | 2025-05-22 |  |
| **[LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning](http://arxiv.org/abs/2505.16933v1)** | 2025-05-22 |  |
| **[A New Fick-Jacobs Derivation with Applications to Computational Branched Diffusion Networks](http://arxiv.org/abs/2501.08247v2)** | 2025-05-22 | 23 pages, 15 figures |
| **[LaViDa: A Large Diffusion Language Model for Multimodal Understanding](http://arxiv.org/abs/2505.16839v1)** | 2025-05-22 | 25 pages, 8 figures |
| **[Make-An-Agent: A Generalizable Policy Network Generator with Behavior-Prompted Diffusion](http://arxiv.org/abs/2407.10973v4)** | 2025-05-22 | <details><summary>Annua...</summary><p>Annual Conference on Neural Information Processing Systems 38</p></details> |
| **[SEED: Speaker Embedding Enhancement Diffusion Model](http://arxiv.org/abs/2505.16798v1)** | 2025-05-22 | <details><summary>Accep...</summary><p>Accepted to Interspeech 2025. The official code can be found at https://github.com/kaistmm/seed-pytorch</p></details> |
| **[REPA Works Until It Doesn't: Early-Stopped, Holistic Alignment Supercharges Diffusion Training](http://arxiv.org/abs/2505.16792v1)** | 2025-05-22 | 24 pages |
| **[Learning Flexible Forward Trajectories for Masked Molecular Diffusion](http://arxiv.org/abs/2505.16790v1)** | 2025-05-22 |  |
| **[Playmate: Flexible Control of Portrait Animation via 3D-Implicit Space Guided Diffusion](http://arxiv.org/abs/2502.07203v3)** | 2025-05-22 |  |
| **[Forward-only Diffusion Probabilistic Models](http://arxiv.org/abs/2505.16733v1)** | 2025-05-22 | <details><summary>Proje...</summary><p>Project page: https://algolzw.github.io/fod</p></details> |

