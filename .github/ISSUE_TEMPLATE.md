---
title: Latest 15 Papers - June 05, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[IllumiCraft: Unified Geometry and Illumination Diffusion for Controllable Video Generation](http://arxiv.org/abs/2506.03150v1)** | 2025-06-03 | Tech Report |
| **[Context as Memory: Scene-Consistent Interactive Long Video Generation with Memory Retrieval](http://arxiv.org/abs/2506.03141v1)** | 2025-06-03 |  |
| **[CamCloneMaster: Enabling Reference-based Camera Control for Video Generation](http://arxiv.org/abs/2506.03140v1)** | 2025-06-03 | <details><summary>Proje...</summary><p>Project Page: https://camclonemaster.github.io/</p></details> |
| **[AnimeShooter: A Multi-Shot Animation Dataset for Reference-Guided Video Generation](http://arxiv.org/abs/2506.03126v1)** | 2025-06-03 | <details><summary>Proje...</summary><p>Project released at: https://qiulu66.github.io/animeshooter/</p></details> |
| **[DCM: Dual-Expert Consistency Model for Efficient and High-Quality Video Generation](http://arxiv.org/abs/2506.03123v1)** | 2025-06-03 |  |
| **[TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via Autoregressive Diffusion Models](http://arxiv.org/abs/2506.03099v1)** | 2025-06-03 |  |
| **[ORV: 4D Occupancy-centric Robot Video Generation](http://arxiv.org/abs/2506.03079v1)** | 2025-06-03 | <details><summary>Proje...</summary><p>Project page: https://orangesodahub.github.io/ORV/ ; Code: https://github.com/OrangeSodahub/ORV</p></details> |
| **[Sparse-vDiT: Unleashing the Power of Sparse Attention to Accelerate Video Diffusion Transformers](http://arxiv.org/abs/2506.03065v1)** | 2025-06-03 |  |
| **[LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering](http://arxiv.org/abs/2506.02733v1)** | 2025-06-03 |  |
| **[OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation](http://arxiv.org/abs/2505.20292v4)** | 2025-06-03 | <details><summary>Code ...</summary><p>Code and Dataset: https://github.com/PKU-YuanGroup/OpenS2V-Nexus</p></details> |
| **[OmniTalker: One-shot Real-time Text-Driven Talking Audio-Video Generation With Multimodal Style Mimicking](http://arxiv.org/abs/2504.02433v2)** | 2025-06-03 | <details><summary>Proje...</summary><p>Project Page https://humanaigc.github.io/omnitalker</p></details> |
| **[Dynamic-I2V: Exploring Image-to-Video Generation Models via Multimodal LLM](http://arxiv.org/abs/2505.19901v3)** | 2025-06-03 |  |
| **[LumosFlow: Motion-Guided Long Video Generation](http://arxiv.org/abs/2506.02497v1)** | 2025-06-03 |  |
| **[SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios](http://arxiv.org/abs/2506.02444v1)** | 2025-06-03 |  |
| **[AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection](http://arxiv.org/abs/2505.15173v2)** | 2025-06-03 |  |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[IllumiCraft: Unified Geometry and Illumination Diffusion for Controllable Video Generation](http://arxiv.org/abs/2506.03150v1)** | 2025-06-03 | Tech Report |
| **[Unifying and extending Diffusion Models through PDEs for solving Inverse Problems](http://arxiv.org/abs/2504.07437v2)** | 2025-06-03 |  |
| **[d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning](http://arxiv.org/abs/2504.12216v2)** | 2025-06-03 | <details><summary>27 pa...</summary><p>27 pages, project page at https://dllm-reasoning.github.io/</p></details> |
| **[EDITOR: Effective and Interpretable Prompt Inversion for Text-to-Image Diffusion Models](http://arxiv.org/abs/2506.03067v1)** | 2025-06-03 |  |
| **[Sparse-vDiT: Unleashing the Power of Sparse Attention to Accelerate Video Diffusion Transformers](http://arxiv.org/abs/2506.03065v1)** | 2025-06-03 |  |
| **[Offline Adaptation of Quadruped Locomotion using Diffusion Models](http://arxiv.org/abs/2411.08832v3)** | 2025-06-03 |  |
| **[Probabilistic Net Load Forecasting for High-Penetration RES Grids Utilizing Enhanced Conditional Diffusion Model](http://arxiv.org/abs/2503.17770v2)** | 2025-06-03 |  |
| **[Diffusion Buffer: Online Diffusion-based Speech Enhancement with Sub-Second Latency](http://arxiv.org/abs/2506.02908v1)** | 2025-06-03 | <details><summary>5 pag...</summary><p>5 pages, 2 figures, Accepted to Interspeech 2025</p></details> |
| **[Diffusion models for Gaussian distributions: Exact solutions and Wasserstein errors](http://arxiv.org/abs/2405.14250v5)** | 2025-06-03 |  |
| **[DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization](http://arxiv.org/abs/2506.02858v1)** | 2025-06-03 | Interspeech 2025 |
| **[FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts](http://arxiv.org/abs/2506.02781v1)** | 2025-06-03 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025</p></details> |
| **[Large Language Models to Diffusion Finetuning](http://arxiv.org/abs/2501.15781v2)** | 2025-06-03 | <details><summary>Camer...</summary><p>Camera-ready version, presented at ICML 2025. Code available at: https://github.com/SakanaAI/L2D</p></details> |
| **[No Training, No Problem: Rethinking Classifier-Free Guidance for Diffusion Models](http://arxiv.org/abs/2407.02687v2)** | 2025-06-03 | <details><summary>Publi...</summary><p>Published as a conference paper at ICLR 2025</p></details> |
| **[Eliminating Oversaturation and Artifacts of High Guidance Scales in Diffusion Models](http://arxiv.org/abs/2410.02416v2)** | 2025-06-03 | <details><summary>Publi...</summary><p>Published as a conference paper at ICLR 2025</p></details> |
| **[Constant Rate Scheduling: Constant-Rate Distributional Change for Efficient Training and Sampling in Diffusion Models](http://arxiv.org/abs/2411.12188v3)** | 2025-06-03 | <details><summary>44 pa...</summary><p>44 pages, 20 figures, 25 tables</p></details> |

