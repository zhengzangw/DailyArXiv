---
title: Latest 15 Papers - August 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Yan: Foundational Interactive Video Generation](http://arxiv.org/abs/2508.08601v2)** | 2025-08-13 |  |
| **[Physical Autoregressive Model for Robotic Manipulation without Action Pretraining](http://arxiv.org/abs/2508.09822v1)** | 2025-08-13 | 16 pages, 6 figures |
| **[Preacher: Paper-to-Video Agentic System](http://arxiv.org/abs/2508.09632v1)** | 2025-08-13 |  |
| **[MoCA: Identity-Preserving Text-to-Video Generation via Mixture of Cross Attention](http://arxiv.org/abs/2508.03034v2)** | 2025-08-13 |  |
| **[SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference](http://arxiv.org/abs/2502.18137v6)** | 2025-08-13 | <details><summary>@inpr...</summary><p>@inproceedings{zhang2025spargeattn, title={Spargeattn: Accurate sparse attention accelerating any model inference}, author={Zhang, Jintao and Xiang, Chendong and Huang, Haofeng and Wei, Jia and Xi, Haocheng and Zhu, Jun and Chen, Jianfei}, booktitle={International Conference on Machine Learning (ICML)}, year={2025} }</p></details> |
| **[From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts](http://arxiv.org/abs/2508.09476v1)** | 2025-08-13 |  |
| **[Human2Robot: Learning Robot Actions from Paired Human-Robot Videos](http://arxiv.org/abs/2502.16587v3)** | 2025-08-13 |  |
| **[X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents](http://arxiv.org/abs/2508.09383v1)** | 2025-08-12 |  |
| **[Turbo-VAED: Fast and Stable Transfer of Video-VAEs to Mobile Devices](http://arxiv.org/abs/2508.09136v1)** | 2025-08-12 |  |
| **[TaoCache: Structure-Maintained Video Generation Acceleration](http://arxiv.org/abs/2508.08978v1)** | 2025-08-12 |  |
| **[Subjective and Objective Quality Assessment of Banding Artifacts on Compressed Videos](http://arxiv.org/abs/2508.08700v1)** | 2025-08-12 |  |
| **[From Slow Bidirectional to Fast Autoregressive Video Diffusion Models](http://arxiv.org/abs/2412.07772v3)** | 2025-08-12 | <details><summary>Proje...</summary><p>Project Page: https://causvid.github.io/</p></details> |
| **[REDUCIO! Generating 1K Video within 16 Seconds using Extremely Compressed Motion Latents](http://arxiv.org/abs/2411.13552v3)** | 2025-08-12 | <details><summary>Accep...</summary><p>Accepted to ICCV2025. Code available at https://github.com/microsoft/Reducio-VAE</p></details> |
| **[Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation](http://arxiv.org/abs/2508.07981v2)** | 2025-08-12 |  |
| **[RealisMotion: Decomposed Human Motion Control and Video Generation in the World Space](http://arxiv.org/abs/2508.08588v1)** | 2025-08-12 | <details><summary>Proje...</summary><p>Project page: https://jingyunliang.github.io/RealisMotion</p></details> |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion](http://arxiv.org/abs/2508.08241v3)** | 2025-08-13 | <details><summary>coin ...</summary><p>coin toss authorship, minor changes</p></details> |
| **[Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models](http://arxiv.org/abs/2508.09968v1)** | 2025-08-13 | <details><summary>Proje...</summary><p>Project page: https://noisehypernetworks.github.io/</p></details> |
| **[LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer](http://arxiv.org/abs/2502.01105v3)** | 2025-08-13 |  |
| **[Stable Diffusion Models are Secretly Good at Visual In-Context Learning](http://arxiv.org/abs/2508.09949v1)** | 2025-08-13 | <details><summary>Accep...</summary><p>Accepted to ICCV 2025</p></details> |
| **[AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using Diffusion Models](http://arxiv.org/abs/2508.09943v1)** | 2025-08-13 |  |
| **[Dequantified Diffusion-Schr{รถ}dinger Bridge for Density Ratio Estimation](http://arxiv.org/abs/2505.05034v4)** | 2025-08-13 |  |
| **[Prototype-Guided Diffusion: Visual Conditioning without External Memory](http://arxiv.org/abs/2508.09922v1)** | 2025-08-13 |  |
| **[Continuous-time q-Learning for Jump-Diffusion Models under Tsallis Entropy](http://arxiv.org/abs/2407.03888v3)** | 2025-08-13 |  |
| **[ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory Prediction for Automated Parking using Diffusion Models](http://arxiv.org/abs/2505.00586v2)** | 2025-08-13 | <details><summary>IROS ...</summary><p>IROS 2025 Camera-Ready Version</p></details> |
| **[Faster Diffusion Models via Higher-Order Approximation](http://arxiv.org/abs/2506.24042v2)** | 2025-08-13 |  |
| **[Enhancing Diffusion Face Generation with Contrastive Embeddings and SegFormer Guidance](http://arxiv.org/abs/2508.09847v1)** | 2025-08-13 | 10 pages, preprint |
| **[PiT: Progressive Diffusion Transformer](http://arxiv.org/abs/2505.13219v4)** | 2025-08-13 |  |
| **[CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data](http://arxiv.org/abs/2508.08173v2)** | 2025-08-13 | <details><summary>Accep...</summary><p>Accepted to IEEE VIS 2025</p></details> |
| **[MangaDiT: Reference-Guided Line Art Colorization with Hierarchical Attention in Diffusion Transformers](http://arxiv.org/abs/2508.09709v1)** | 2025-08-13 | <details><summary>Codes...</summary><p>Codes and benchmarks will be released soon</p></details> |
| **[GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors](http://arxiv.org/abs/2508.09667v1)** | 2025-08-13 |  |

