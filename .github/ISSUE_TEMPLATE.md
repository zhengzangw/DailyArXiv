---
title: Latest 15 Papers - February 12, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT](http://arxiv.org/abs/2502.06782v1)** | 2025-02-10 |  |
| **[History-Guided Video Diffusion](http://arxiv.org/abs/2502.06764v1)** | 2025-02-10 | <details><summary>Proje...</summary><p>Project Website: https://boyuan.space/history-guidance</p></details> |
| **[Se√±orita-2M: A High-Quality Instruction-based Dataset for General Video Editing by Video Specialists](http://arxiv.org/abs/2502.06734v1)** | 2025-02-10 |  |
| **[Do generative video models learn physical principles from watching videos?](http://arxiv.org/abs/2501.09038v2)** | 2025-02-10 |  |
| **[TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models](http://arxiv.org/abs/2502.06608v1)** | 2025-02-10 |  |
| **[HumanDiT: Pose-Guided Diffusion Transformer for Long-form Human Motion Video Generation](http://arxiv.org/abs/2502.04847v2)** | 2025-02-10 | <details><summary>https...</summary><p>https://agnjason.github.io/HumanDiT-page/</p></details> |
| **[CustomVideoX: 3D Reference Attention Driven Dynamic Adaptation for Zero-Shot Customized Video Diffusion Transformers](http://arxiv.org/abs/2502.06527v1)** | 2025-02-10 | 13 pages, 10 figures |
| **[SageAttention2: Efficient Attention with Thorough Outlier Smoothing and Per-thread INT4 Quantization](http://arxiv.org/abs/2411.10958v4)** | 2025-02-10 |  |
| **[Goku: Flow Based Video Generative Foundation Models](http://arxiv.org/abs/2502.04896v2)** | 2025-02-10 | <details><summary>Demo:...</summary><p>Demo: https://saiyan-world.github.io/goku/</p></details> |
| **[Efficient-vDiT: Efficient Video Diffusion Transformers With Attention Tile](http://arxiv.org/abs/2502.06155v1)** | 2025-02-10 |  |
| **[VideoAgent: Self-Improving Video Generation](http://arxiv.org/abs/2410.10076v3)** | 2025-02-09 |  |
| **[Towards AI-driven Sign Language Generation with Non-manual Markers](http://arxiv.org/abs/2502.05661v1)** | 2025-02-08 | Accepted to CHI 2025 |
| **[Training-Free Constrained Generation With Stable Diffusion Models](http://arxiv.org/abs/2502.05625v1)** | 2025-02-08 |  |
| **[UniForm: A Unified Diffusion Transformer for Audio-Video Generation](http://arxiv.org/abs/2502.03897v2)** | 2025-02-08 | <details><summary>Our d...</summary><p>Our demos are available at https://uniform-t2av.github.io/</p></details> |
| **[A Physical Coherence Benchmark for Evaluating Video Generation Models via Optical Flow-guided Frame Prediction](http://arxiv.org/abs/2502.05503v1)** | 2025-02-08 |  |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Grounding Text-to-Image Diffusion Models for Controlled High-Quality Image Generation](http://arxiv.org/abs/2501.09194v2)** | 2025-02-10 |  |
| **[Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions](http://arxiv.org/abs/2502.06768v1)** | 2025-02-10 |  |
| **[History-Guided Video Diffusion](http://arxiv.org/abs/2502.06764v1)** | 2025-02-10 | <details><summary>Proje...</summary><p>Project Website: https://boyuan.space/history-guidance</p></details> |
| **[Unleashing the Potential of Pre-Trained Diffusion Models for Generalizable Person Re-Identification](http://arxiv.org/abs/2502.06619v1)** | 2025-02-10 |  |
| **[Surrogate models for diffusion on graphs via sparse polynomials](http://arxiv.org/abs/2502.06595v1)** | 2025-02-10 |  |
| **[Diffusion Models for Computational Neuroimaging: A Survey](http://arxiv.org/abs/2502.06552v1)** | 2025-02-10 | 9 pages, 1 figure |
| **[HumanDiT: Pose-Guided Diffusion Transformer for Long-form Human Motion Video Generation](http://arxiv.org/abs/2502.04847v2)** | 2025-02-10 | <details><summary>https...</summary><p>https://agnjason.github.io/HumanDiT-page/</p></details> |
| **[CustomVideoX: 3D Reference Attention Driven Dynamic Adaptation for Zero-Shot Customized Video Diffusion Transformers](http://arxiv.org/abs/2502.06527v1)** | 2025-02-10 | 13 pages, 10 figures |
| **[Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation](http://arxiv.org/abs/2502.06516v1)** | 2025-02-10 | 29 pages, 11 figures |
| **[WyckoffDiff - A Generative Diffusion Model for Crystal Symmetry](http://arxiv.org/abs/2502.06485v1)** | 2025-02-10 |  |
| **[Compressed Image Generation with Denoising Diffusion Codebook Models](http://arxiv.org/abs/2502.01189v3)** | 2025-02-10 | <details><summary>Code ...</summary><p>Code and demo are available at https://ddcm-2025.github.io/</p></details> |
| **[Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising](http://arxiv.org/abs/2502.06432v1)** | 2025-02-10 |  |
| **[Habitizing Diffusion Planning for Efficient and Effective Decision Making](http://arxiv.org/abs/2502.06401v1)** | 2025-02-10 |  |
| **[Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo](http://arxiv.org/abs/2502.06379v1)** | 2025-02-10 |  |
| **[Guidance-base Diffusion Models for Improving Photoacoustic Image Quality](http://arxiv.org/abs/2502.06354v1)** | 2025-02-10 |  |

