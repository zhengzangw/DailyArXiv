---
title: Latest 15 Papers - January 07, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VINO: A Unified Visual Generator with Interleaved OmniModal Context](https://arxiv.org/abs/2601.02358v1)** | 2026-01-05 | <details><summary>Proje...</summary><p>Project page: https://sotamak1r.github.io/VINO-web/</p></details> |
| **[Compositional Diffusion with Guided Search for Long-Horizon Planning](https://arxiv.org/abs/2601.00126v2)** | 2026-01-05 | 38 pages, 18 figures |
| **[NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation](https://arxiv.org/abs/2601.02204v1)** | 2026-01-05 | <details><summary>Proje...</summary><p>Project page: https://github.com/ByteVisionLab/NextFlow</p></details> |
| **[SingingBot: An Avatar-Driven System for Robotic Face Singing Performance](https://arxiv.org/abs/2601.02125v1)** | 2026-01-05 |  |
| **[MagicFight: Personalized Martial Arts Combat Video Generation](https://arxiv.org/abs/2601.02107v1)** | 2026-01-05 | <details><summary>Accep...</summary><p>Accepted by ACM MM 2024</p></details> |
| **[VisionReward: Fine-Grained Multi-Dimensional Human Preference Learning for Image and Video Generation](https://arxiv.org/abs/2412.21059v4)** | 2026-01-05 | 27 pages |
| **[MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning](https://arxiv.org/abs/2601.01568v1)** | 2026-01-04 |  |
| **[DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving](https://arxiv.org/abs/2601.01528v1)** | 2026-01-04 | <details><summary>10 pa...</summary><p>10 pages, 4 figures; Project Website: https://drivinggen-bench.github.io/</p></details> |
| **[Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding](https://arxiv.org/abs/2601.01352v1)** | 2026-01-04 |  |
| **[MotionCharacter: Fine-Grained Motion Controllable Human Video Generation](https://arxiv.org/abs/2411.18281v3)** | 2026-01-03 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[VEAT Quantifies Implicit Associations in Text-to-Video Generator Sora and Reveals Challenges in Bias Mitigation](https://arxiv.org/abs/2601.00996v1)** | 2026-01-02 | <details><summary>The I...</summary><p>The International Association for Safe & Ethical AI (IASEAI)</p></details> |
| **[PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education](https://arxiv.org/abs/2601.00943v1)** | 2026-01-02 | <details><summary>Accep...</summary><p>Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026</p></details> |
| **[Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678v1)** | 2026-01-02 |  |
| **[NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393v1)** | 2026-01-01 | <details><summary>Proje...</summary><p>Project Page: https://neoverse-4d.github.io</p></details> |
| **[TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051v1)** | 2025-12-31 |  |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors](https://arxiv.org/abs/2601.02359v1)** | 2026-01-05 | <details><summary>17 pa...</summary><p>17 pages, 8 figures, 11 tables; project page: https://mapooon.github.io/ExposeAnyonePage/</p></details> |
| **[DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies](https://arxiv.org/abs/2601.02267v1)** | 2026-01-05 | <details><summary>Page:...</summary><p>Page: https://wrk226.github.io/DiffProxy.html, Code: https://github.com/wrk226/DiffProxy</p></details> |
| **[DogFit: Domain-guided Fine-tuning for Efficient Transfer Learning of Diffusion Models](https://arxiv.org/abs/2508.05685v6)** | 2026-01-05 | <details><summary>Accep...</summary><p>Accepted for poster presentation at AAAI 2026</p></details> |
| **[CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models](https://arxiv.org/abs/2601.02236v1)** | 2026-01-05 | 33 pages, 7 figures |
| **[Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion](https://arxiv.org/abs/2601.02211v1)** | 2026-01-05 | 11 pages |
| **[Compositional Diffusion with Guided Search for Long-Horizon Planning](https://arxiv.org/abs/2601.00126v2)** | 2026-01-05 | 38 pages, 18 figures |
| **[InpaintHuman: Reconstructing Occluded Humans with Multi-Scale UV Mapping and Identity-Preserving Diffusion Inpainting](https://arxiv.org/abs/2601.02098v1)** | 2026-01-05 |  |
| **[Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows](https://arxiv.org/abs/2601.02076v1)** | 2026-01-05 |  |
| **[Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity](https://arxiv.org/abs/2505.09922v3)** | 2026-01-05 |  |
| **[On Exact Editing of Flow-Based Diffusion Models](https://arxiv.org/abs/2512.24015v2)** | 2026-01-05 |  |
| **[GDRO: Group-level Reward Post-training Suitable for Diffusion Models](https://arxiv.org/abs/2601.02036v1)** | 2026-01-05 |  |
| **[Learning Diffusion Policy from Primitive Skills for Robot Manipulation](https://arxiv.org/abs/2601.01948v1)** | 2026-01-05 | Accepted to AAAI2026 |
| **[Cosmos: Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170v3)** | 2026-01-05 |  |
| **[RS-Prune: Training-Free Data Pruning at High Ratios for Efficient Remote Sensing Diffusion Foundation Models](https://arxiv.org/abs/2512.23239v2)** | 2026-01-05 |  |
| **[Learning Action Hierarchies via Hybrid Geometric Diffusion](https://arxiv.org/abs/2601.01914v1)** | 2026-01-05 | Accepted at WACV-26 |

