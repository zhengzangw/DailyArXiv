---
title: Latest 15 Papers - August 25, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Scaling Group Inference for Diverse and High-Quality Generation](http://arxiv.org/abs/2508.15773v1)** | 2025-08-21 | <details><summary>Proje...</summary><p>Project website: https://www.cs.cmu.edu/~group-inference, GitHub: https://github.com/GaParmar/group-inference</p></details> |
| **[CineScale: Free Lunch in High-Resolution Cinematic Visual Generation](http://arxiv.org/abs/2508.15774v1)** | 2025-08-21 | <details><summary>CineS...</summary><p>CineScale is an extended work of FreeScale (ICCV 2025). Project Page: https://eyeline-labs.github.io/CineScale/, Code Repo: https://github.com/Eyeline-Labs/CineScale</p></details> |
| **[Waver: Wave Your Way to Lifelike Video Generation](http://arxiv.org/abs/2508.15761v1)** | 2025-08-21 |  |
| **[TiP4GEN: Text to Immersive Panorama 4D Scene Generation](http://arxiv.org/abs/2508.12415v2)** | 2025-08-21 | <details><summary>Accep...</summary><p>Accepted In Proceedings of the 33rd ACM International Conference on Multimedia (MM' 25)</p></details> |
| **[WorldWeaver: Generating Long-Horizon Video Worlds via Rich Perception](http://arxiv.org/abs/2508.15720v1)** | 2025-08-21 | <details><summary>Proje...</summary><p>Project page: https://johanan528.github.io/worldweaver_web/</p></details> |
| **[Capturing Stable HDR Videos Using a Dual-Camera System](http://arxiv.org/abs/2507.06593v2)** | 2025-08-21 |  |
| **[Preacher: Paper-to-Video Agentic System](http://arxiv.org/abs/2508.09632v4)** | 2025-08-21 | <details><summary>Inclu...</summary><p>Include some mistakes</p></details> |
| **[Omni-Video: Democratizing Unified Video Understanding and Generation](http://arxiv.org/abs/2507.06119v3)** | 2025-08-21 | <details><summary>Techn...</summary><p>Technical report, project page: https://howellyoung-s.github.io/OmniVideo_project/</p></details> |
| **[Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models](http://arxiv.org/abs/2412.09645v3)** | 2025-08-20 | <details><summary>Equal...</summary><p>Equal contributions from first three authors. Project page: https://vchitect.github.io/Evaluation-Agent-project Code: https://github.com/Vchitect/Evaluation-Agent</p></details> |
| **[VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic Faithfulness](http://arxiv.org/abs/2503.21755v2)** | 2025-08-20 | <details><summary>Equal...</summary><p>Equal contributions from first two authors. Project page: https://vchitect.github.io/VBench-2.0-project/ Code: https://github.com/Vchitect/VBench</p></details> |
| **[MAViS: A Multi-Agent Framework for Long-Sequence Video Storytelling](http://arxiv.org/abs/2508.08487v3)** | 2025-08-20 | <details><summary>Video...</summary><p>Video Generation Agent</p></details> |
| **[Efficient Long-duration Talking Video Synthesis with Linear Diffusion Transformer under Multimodal Guidance](http://arxiv.org/abs/2411.16748v3)** | 2025-08-20 | 13 pages, 11 figures |
| **[MinD: Learning A Dual-System World Model for Real-Time Planning and Implicit Risk Analysis](http://arxiv.org/abs/2506.18897v2)** | 2025-08-20 |  |
| **[DreamSwapV: Mask-guided Subject Swapping for Any Customized Video Editing](http://arxiv.org/abs/2508.14465v1)** | 2025-08-20 |  |
| **[MoVieDrive: Multi-Modal Multi-View Urban Scene Video Generation](http://arxiv.org/abs/2508.14327v1)** | 2025-08-20 | Technical Report |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Probability Density from Latent Diffusion Models for Out-of-Distribution Detection](http://arxiv.org/abs/2508.15737v1)** | 2025-08-21 | ECAI 2025 |
| **[When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding](http://arxiv.org/abs/2508.15641v1)** | 2025-08-21 |  |
| **[Fast-DDPM: Fast Denoising Diffusion Probabilistic Models for Medical Image-to-Image Generation](http://arxiv.org/abs/2405.14802v3)** | 2025-08-21 |  |
| **[Mean-Field Langevin Diffusions with Density-dependent Temperature](http://arxiv.org/abs/2507.20958v2)** | 2025-08-21 |  |
| **[Dream 7B: Diffusion Large Language Models](http://arxiv.org/abs/2508.15487v1)** | 2025-08-21 |  |
| **[ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction](http://arxiv.org/abs/2508.08170v2)** | 2025-08-21 |  |
| **[Hybrid Autoregressive-Diffusion Model for Real-Time Streaming Sign Language Production](http://arxiv.org/abs/2507.09105v2)** | 2025-08-21 | <details><summary>The a...</summary><p>The authors have withdrawn this manuscript because the current version requires substantial revisions and is no longer suitable for posting</p></details> |
| **[Latent Interpolation Learning Using Diffusion Models for Cardiac Volume Reconstruction](http://arxiv.org/abs/2508.13826v3)** | 2025-08-21 |  |
| **[VideoEraser: Concept Erasure in Text-to-Video Diffusion Models](http://arxiv.org/abs/2508.15314v1)** | 2025-08-21 | <details><summary>To ap...</summary><p>To appear in the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP)</p></details> |
| **[Modeling Long-term User Behaviors with Diffusion-driven Multi-interest Network for CTR Prediction](http://arxiv.org/abs/2508.15311v1)** | 2025-08-21 |  |
| **[Generation of structure-guided pMHC-I libraries using Diffusion Models](http://arxiv.org/abs/2507.08902v2)** | 2025-08-21 | <details><summary>Accep...</summary><p>Accepted to the The 2nd Workshop on Generative AI and Biology ICML Workshop 2025</p></details> |
| **[CopyrightShield: Enhancing Diffusion Model Security against Copyright Infringement Attacks](http://arxiv.org/abs/2412.01528v2)** | 2025-08-21 |  |
| **[Pathology-Informed Latent Diffusion Model for Anomaly Detection in Lymph Node Metastasis](http://arxiv.org/abs/2508.15236v1)** | 2025-08-21 |  |
| **[Pretrained Diffusion Models Are Inherently Skipped-Step Samplers](http://arxiv.org/abs/2508.15233v1)** | 2025-08-21 |  |
| **[DIFFA: Large Language Diffusion Models Can Listen and Understand](http://arxiv.org/abs/2507.18452v2)** | 2025-08-21 |  |

