---
title: Latest 15 Papers - October 06, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Inferring Dynamic Physical Properties from Video Foundation Models](http://arxiv.org/abs/2510.02311v1)** | 2025-10-02 |  |
| **[MultiModal Action Conditioned Video Generation](http://arxiv.org/abs/2510.02287v1)** | 2025-10-02 |  |
| **[Learning to Generate Object Interactions with Physics-Guided Video Diffusion](http://arxiv.org/abs/2510.02284v1)** | 2025-10-02 |  |
| **[Self-Forcing++: Towards Minute-Scale High-Quality Video Generation](http://arxiv.org/abs/2510.02283v1)** | 2025-10-02 | preprint |
| **[TempoControl: Temporal Attention Guidance for Text-to-Video Models](http://arxiv.org/abs/2510.02226v1)** | 2025-10-02 | Under Review |
| **[Multi-marginal temporal Schr√∂dinger Bridge Matching for video generation from unpaired data](http://arxiv.org/abs/2510.01894v1)** | 2025-10-02 | <details><summary>Under...</summary><p>Under review. Code available at https://github.com/tgravier/MMDSBM-pytorch . Additional experiment materials available at https://mmdsbm.notion.site</p></details> |
| **[VideoGen-of-Thought: Step-by-step generating multi-shot video with minimal manual intervention](http://arxiv.org/abs/2412.02259v3)** | 2025-10-02 | <details><summary>Code:...</summary><p>Code: https://github.com/DuNGEOnmassster/VideoGen-of-Thought.git; Webpage: https://cheliosoops.github.io/VGoT/</p></details> |
| **[Pack and Force Your Memory: Long-form and Consistent Video Generation](http://arxiv.org/abs/2510.01784v1)** | 2025-10-02 |  |
| **[AniMaker: Multi-Agent Animated Storytelling with MCTS-Driven Clip Generation](http://arxiv.org/abs/2506.10540v2)** | 2025-10-02 |  |
| **[Diffusion Adversarial Post-Training for One-Step Video Generation](http://arxiv.org/abs/2501.08316v3)** | 2025-10-01 | ICML 2025 |
| **[Autoregressive Adversarial Post-Training for Real-Time Interactive Video Generation](http://arxiv.org/abs/2506.09350v2)** | 2025-10-01 | NeurIPS 2025 |
| **[IMAGEdit: Let Any Subject Transform](http://arxiv.org/abs/2510.01186v1)** | 2025-10-01 |  |
| **[EvoWorld: Evolving Panoramic World Generation with Explicit 3D Memory](http://arxiv.org/abs/2510.01183v1)** | 2025-10-01 | <details><summary>Code ...</summary><p>Code available at: https://github.com/JiahaoPlus/EvoWorld</p></details> |
| **[Code2Video: A Code-centric Paradigm for Educational Video Generation](http://arxiv.org/abs/2510.01174v1)** | 2025-10-01 | <details><summary>Proje...</summary><p>Project Page: https://showlab.github.io/Code2Video/</p></details> |
| **[SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference](http://arxiv.org/abs/2502.18137v7)** | 2025-10-01 | <details><summary>@inpr...</summary><p>@inproceedings{zhang2025spargeattn, title={Spargeattn: Accurate sparse attention accelerating any model inference}, author={Zhang, Jintao and Xiang, Chendong and Huang, Haofeng and Wei, Jia and Xi, Haocheng and Zhu, Jun and Chen, Jianfei}, booktitle={International Conference on Machine Learning (ICML)}, year={2025} }</p></details> |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Diffusion Models and the Manifold Hypothesis: Log-Domain Smoothing is Geometry Adaptive](http://arxiv.org/abs/2510.02305v1)** | 2025-10-02 |  |
| **[Continual Personalization for Diffusion Models](http://arxiv.org/abs/2510.02296v1)** | 2025-10-02 |  |
| **[Test-Time Anchoring for Discrete Diffusion Posterior Sampling](http://arxiv.org/abs/2510.02291v1)** | 2025-10-02 | Preprint |
| **[Learning to Generate Object Interactions with Physics-Guided Video Diffusion](http://arxiv.org/abs/2510.02284v1)** | 2025-10-02 |  |
| **[Diffusion Transformers for Imputation: Statistical Efficiency and Uncertainty Quantification](http://arxiv.org/abs/2510.02216v1)** | 2025-10-02 | <details><summary>49 pa...</summary><p>49 pages, 4 figures. Accepted as a poster at NeurIPS 2025</p></details> |
| **[DiFFPO: Training Diffusion LLMs to Reason Fast and Furious via Reinforcement Learning](http://arxiv.org/abs/2510.02212v1)** | 2025-10-02 |  |
| **[Uncovering Semantic Selectivity of Latent Groups in Higher Visual Cortex with Mutual Information-Guided Diffusion](http://arxiv.org/abs/2510.02182v1)** | 2025-10-02 |  |
| **[One-Step Residual Shifting Diffusion for Image Super-Resolution via Distillation](http://arxiv.org/abs/2503.13358v3)** | 2025-10-02 |  |
| **[Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation](http://arxiv.org/abs/2509.24798v2)** | 2025-10-02 | 9 pages, 26 figures |
| **[VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and Segmentation](http://arxiv.org/abs/2510.02086v1)** | 2025-10-02 |  |
| **[DiCache: Let Diffusion Model Determine Its Own Cache](http://arxiv.org/abs/2508.17356v2)** | 2025-10-02 | <details><summary>Proje...</summary><p>Project Page: https://bujiazi.github.io/dicache.github.io/ Code: https://github.com/Bujiazi/DiCache</p></details> |
| **[Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects](http://arxiv.org/abs/2510.02069v1)** | 2025-10-02 |  |
| **[Zero-shot Human Pose Estimation using Diffusion-based Inverse solvers](http://arxiv.org/abs/2510.02043v1)** | 2025-10-02 |  |
| **[Enhanced DACER Algorithm with High Diffusion Efficiency](http://arxiv.org/abs/2505.23426v2)** | 2025-10-02 |  |
| **[There and Back Again: On the relation between Noise and Image Inversions in Diffusion Models](http://arxiv.org/abs/2410.23530v4)** | 2025-10-02 | Preprint |

