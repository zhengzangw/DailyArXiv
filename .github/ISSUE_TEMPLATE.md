---
title: Latest 15 Papers - April 09, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[One-Minute Video Generation with Test-Time Training](http://arxiv.org/abs/2504.05298v1)** | 2025-04-07 | CVPR 2025 |
| **[Track4Gen: Teaching Video Diffusion Models to Track Points Improves Video Generation](http://arxiv.org/abs/2412.06016v3)** | 2025-04-07 | <details><summary>CVPR ...</summary><p>CVPR 2025, Project page: hyeonho99.github.io/track4gen</p></details> |
| **[Video-Bench: Human-Aligned Video Generation Benchmark](http://arxiv.org/abs/2504.04907v1)** | 2025-04-07 | Accepted by CVPR'25 |
| **[Audio-visual Controlled Video Diffusion with Masked Selective State Spaces Modeling for Natural Talking Head Generation](http://arxiv.org/abs/2504.02542v3)** | 2025-04-07 |  |
| **[Detecting AI-Generated Video via Frame Consistency](http://arxiv.org/abs/2402.02085v7)** | 2025-04-07 |  |
| **[MagicTime: Time-lapse Video Generation Models as Metamorphic Simulators](http://arxiv.org/abs/2404.05014v2)** | 2025-04-06 | TPAMI 2025 |
| **[CoGen: 3D Consistent Video Generation via Adaptive Conditioning for Autonomous Driving](http://arxiv.org/abs/2503.22231v2)** | 2025-04-05 |  |
| **[Video4DGen: Enhancing Video and 4D Generation through Mutual Optimization](http://arxiv.org/abs/2504.04153v1)** | 2025-04-05 | <details><summary>Publi...</summary><p>Published in TPAMI 2025. Code: https://github.com/yikaiw/Vidu4D, Project page: https://video4dgen.github.io</p></details> |
| **[Multi-identity Human Image Animation with Structural Video Diffusion](http://arxiv.org/abs/2504.04126v1)** | 2025-04-05 | 11 pages |
| **[CyberHost: Taming Audio-driven Avatar Diffusion Model with Region Codebook Attention](http://arxiv.org/abs/2409.01876v3)** | 2025-04-05 | <details><summary>ICLR ...</summary><p>ICLR 2025 (Oral), Homepage: https://cyberhost.github.io/</p></details> |
| **[Can You Count to Nine? A Human Evaluation Benchmark for Counting Limits in Modern Text-to-Video Models](http://arxiv.org/abs/2504.04051v1)** | 2025-04-05 |  |
| **[DiTaiListener: Controllable High Fidelity Listener Video Generation with Diffusion](http://arxiv.org/abs/2504.04010v1)** | 2025-04-05 | <details><summary>Proje...</summary><p>Project page: https://havent-invented.github.io/DiTaiListener</p></details> |
| **[InterDyn: Controllable Interactive Dynamics with Video Diffusion Models](http://arxiv.org/abs/2412.11785v3)** | 2025-04-04 |  |
| **[VLIPP: Towards Physically Plausible Video Generation with Vision and Language Informed Physical Prior](http://arxiv.org/abs/2503.23368v3)** | 2025-04-04 | 18 pages, 11 figures |
| **[Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency](http://arxiv.org/abs/2409.02634v3)** | 2025-04-04 | <details><summary>ICLR ...</summary><p>ICLR 2025 (Oral), Homepage: https://loopyavatar.github.io/</p></details> |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Dimension-Free Convergence of Diffusion Models for Approximate Gaussian Mixtures](http://arxiv.org/abs/2504.05300v1)** | 2025-04-07 |  |
| **[AnomalousNet: A Hybrid Approach with Attention U-Nets and Change Point Detection for Accurate Characterization of Anomalous Diffusion in Video Data](http://arxiv.org/abs/2504.05271v1)** | 2025-04-07 | 20 pages, 9 figures |
| **[DiffPatch: Generating Customizable Adversarial Patches using Diffusion Models](http://arxiv.org/abs/2412.01440v3)** | 2025-04-07 |  |
| **[Controlled Latent Diffusion Models for 3D Porous Media Reconstruction](http://arxiv.org/abs/2503.24083v2)** | 2025-04-07 | 58 pages |
| **[DA2Diff: Exploring Degradation-aware Adaptive Diffusion Priors for All-in-One Weather Restoration](http://arxiv.org/abs/2504.05135v1)** | 2025-04-07 |  |
| **[Turing instability for nonlocal heterogeneous reaction-diffusion systems: A computer-assisted proof approach](http://arxiv.org/abs/2504.05066v1)** | 2025-04-07 |  |
| **[CleanDIFT: Diffusion Features without Noise](http://arxiv.org/abs/2412.03439v2)** | 2025-04-07 | <details><summary>for t...</summary><p>for the project page and code, view https://compvis.github.io/cleandift/</p></details> |
| **[Graph-based Diffusion Model for Collaborative Filtering](http://arxiv.org/abs/2504.05029v1)** | 2025-04-07 |  |
| **[No Re-Train, More Gain: Upgrading Backbones with Diffusion model for Pixel-Wise and Weakly-Supervised Few-Shot Segmentation](http://arxiv.org/abs/2407.16182v2)** | 2025-04-07 | 9 figures |
| **[REWIND: Real-Time Egocentric Whole-Body Motion Diffusion with Exemplar-Based Identity Conditioning](http://arxiv.org/abs/2504.04956v1)** | 2025-04-07 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025, project page: https://jyunlee.github.io/projects/rewind/</p></details> |
| **[Anisotropic space-time goal-oriented error control and mesh adaptivity for convection-diffusion-reaction equations](http://arxiv.org/abs/2504.04951v1)** | 2025-04-07 |  |
| **[Track4Gen: Teaching Video Diffusion Models to Track Points Improves Video Generation](http://arxiv.org/abs/2412.06016v3)** | 2025-04-07 | <details><summary>CVPR ...</summary><p>CVPR 2025, Project page: hyeonho99.github.io/track4gen</p></details> |
| **[Audio-visual Controlled Video Diffusion with Masked Selective State Spaces Modeling for Natural Talking Head Generation](http://arxiv.org/abs/2504.02542v3)** | 2025-04-07 |  |
| **[Latent Feature and Attention Dual Erasure Attack against Multi-View Diffusion Models for 3D Assets Protection](http://arxiv.org/abs/2408.11408v2)** | 2025-04-07 | <details><summary>This ...</summary><p>This paper has been accepted by ICME 2025</p></details> |
| **[A Survey on Personalized Content Synthesis with Diffusion Models](http://arxiv.org/abs/2405.05538v3)** | 2025-04-07 |  |

