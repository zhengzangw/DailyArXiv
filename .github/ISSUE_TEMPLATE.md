---
title: Latest 15 Papers - February 14, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CineMaster: A 3D-Aware and Controllable Framework for Cinematic Text-to-Video Generation](http://arxiv.org/abs/2502.08639v1)** | 2025-02-12 |  |
| **[Next Block Prediction: Video Generation via Semi-Autoregressive Modeling](http://arxiv.org/abs/2502.07737v2)** | 2025-02-12 | <details><summary>proje...</summary><p>project page: https://renshuhuai-andy.github.io/NBP-project/</p></details> |
| **[Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT](http://arxiv.org/abs/2502.06782v2)** | 2025-02-12 |  |
| **[FloVD: Optical Flow Meets Video Diffusion Model for Enhanced Camera-Controlled Video Synthesis](http://arxiv.org/abs/2502.08244v1)** | 2025-02-12 | <details><summary>Proje...</summary><p>Project website: https://jinwonjoon.github.io/flovd_site/</p></details> |
| **[Learning Human Skill Generators at Key-Step Levels](http://arxiv.org/abs/2502.08234v1)** | 2025-02-12 |  |
| **[AnyCharV: Bootstrap Controllable Character Video Generation with Fine-to-Coarse Guidance](http://arxiv.org/abs/2502.08189v1)** | 2025-02-12 | <details><summary>15 pa...</summary><p>15 pages, 9 figures, 4 tables</p></details> |
| **[VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation](http://arxiv.org/abs/2502.07531v2)** | 2025-02-12 |  |
| **[Magic 1-For-1: Generating One Minute Video Clips within One Minute](http://arxiv.org/abs/2502.07701v1)** | 2025-02-11 |  |
| **[Enhance-A-Video: Better Generated Video for Free](http://arxiv.org/abs/2502.07508v1)** | 2025-02-11 |  |
| **[Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos](http://arxiv.org/abs/2502.07327v1)** | 2025-02-11 |  |
| **[Articulate That Object Part (ATOP): 3D Part Articulation from Text and Motion Personalization](http://arxiv.org/abs/2502.07278v1)** | 2025-02-11 | <details><summary>Techn...</summary><p>Technical Report, 16 pages</p></details> |
| **[Contextual Gesture: Co-Speech Gesture Video Generation through Context-aware Gesture Representation](http://arxiv.org/abs/2502.07239v1)** | 2025-02-11 |  |
| **[Lotus: Creating Short Videos From Long Videos With Abstractive and Extractive Summarization](http://arxiv.org/abs/2502.07096v1)** | 2025-02-10 | <details><summary>15 pa...</summary><p>15 pages, 9 figures, ACM IUI 2025</p></details> |
| **[Conditional diffusion model with spatial attention and latent embedding for medical image segmentation](http://arxiv.org/abs/2502.06997v1)** | 2025-02-10 | <details><summary>11 pa...</summary><p>11 pages, 2 figures, 3 tables, Accepted in MICCAI 2024</p></details> |
| **[History-Guided Video Diffusion](http://arxiv.org/abs/2502.06764v1)** | 2025-02-10 | <details><summary>Proje...</summary><p>Project Website: https://boyuan.space/history-guidance</p></details> |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SwiftSketch: A Diffusion Model for Image-to-Vector Sketch Generation](http://arxiv.org/abs/2502.08642v1)** | 2025-02-12 | <details><summary>https...</summary><p>https://swiftsketch.github.io/</p></details> |
| **[A provably stable numerical method for the anisotropic diffusion equation in confined magnetic fields](http://arxiv.org/abs/2306.00423v4)** | 2025-02-12 | 30 pages, 11 figures |
| **[Enhancing Diffusion Models Efficiency by Disentangling Total-Variance and Signal-to-Noise Ratio](http://arxiv.org/abs/2502.08598v1)** | 2025-02-12 |  |
| **[Ultrasound Image Generation using Latent Diffusion Models](http://arxiv.org/abs/2502.08580v1)** | 2025-02-12 | <details><summary>6 pag...</summary><p>6 pages conference paper for SPIE medical imaging</p></details> |
| **[BCDDM: Branch-Corrected Denoising Diffusion Model for Black Hole Image Generation](http://arxiv.org/abs/2502.08528v1)** | 2025-02-12 |  |
| **[One-Shot Federated Learning with Classifier-Free Diffusion Models](http://arxiv.org/abs/2502.08488v1)** | 2025-02-12 |  |
| **[GravMAD: Grounded Spatial Value Maps Guided Action Diffusion for Generalized 3D Manipulation](http://arxiv.org/abs/2409.20154v4)** | 2025-02-12 | <details><summary>ICLR ...</summary><p>ICLR 2025. The first two authors contributed equally</p></details> |
| **[X-Diffusion: Generating Detailed 3D MRI Volumes From a Single Image Using Cross-Sectional Diffusion Models](http://arxiv.org/abs/2404.19604v2)** | 2025-02-12 | <details><summary>prepr...</summary><p>preprint, project website: https://emmanuelleb985.github.io/XDiffusion/</p></details> |
| **[A Survey on Pre-Trained Diffusion Model Distillations](http://arxiv.org/abs/2502.08364v1)** | 2025-02-12 |  |
| **[TRADES: Generating Realistic Market Simulations with Diffusion Models](http://arxiv.org/abs/2502.07071v2)** | 2025-02-12 | 14 pages |
| **[Unsupervised Training of Diffusion Models for Feasible Solution Generation in Neural Combinatorial Optimization](http://arxiv.org/abs/2411.00003v4)** | 2025-02-12 |  |
| **[A posteriori error control for a finite volume scheme for a cross-diffusion model of ion transport](http://arxiv.org/abs/2502.08306v1)** | 2025-02-12 | 27 pages, 2 tables |
| **[DGQ: Distribution-Aware Group Quantization for Text-to-Image Diffusion Models](http://arxiv.org/abs/2501.04304v2)** | 2025-02-12 | <details><summary>Accep...</summary><p>Accepted ICLR 2025. Project page: https://ugonfor.kr/DGQ</p></details> |
| **[FloVD: Optical Flow Meets Video Diffusion Model for Enhanced Camera-Controlled Video Synthesis](http://arxiv.org/abs/2502.08244v1)** | 2025-02-12 | <details><summary>Proje...</summary><p>Project website: https://jinwonjoon.github.io/flovd_site/</p></details> |
| **[One Diffusion Step to Real-World Super-Resolution via Flow Trajectory Distillation](http://arxiv.org/abs/2502.01993v2)** | 2025-02-12 |  |

