---
title: Latest 15 Papers - January 06, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678v1)** | 2026-01-02 |  |
| **[NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393v1)** | 2026-01-01 | <details><summary>Proje...</summary><p>Project Page: https://neoverse-4d.github.io</p></details> |
| **[Compositional Diffusion with Guided search for Long-Horizon Planning](https://arxiv.org/abs/2601.00126v1)** | 2025-12-31 | 38 pages, 18 figures |
| **[TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051v1)** | 2025-12-31 |  |
| **[VIPER: Process-aware Evaluation for Generative Video Reasoning](https://arxiv.org/abs/2512.24952v1)** | 2025-12-31 | Work in progress |
| **[Inference-based GAN Video Generation](https://arxiv.org/abs/2512.21776v2)** | 2025-12-31 |  |
| **[Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow](https://arxiv.org/abs/2512.24766v1)** | 2025-12-31 | <details><summary>Proje...</summary><p>Project website: https://dream2flow.github.io/</p></details> |
| **[FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation](https://arxiv.org/abs/2512.24724v1)** | 2025-12-31 | <details><summary>Proje...</summary><p>Project page: https://jibin86.github.io/flowblending_project_page</p></details> |
| **[OnlineVPO: Align Video Diffusion Model with Online Video-Centric Preference Optimization](https://arxiv.org/abs/2412.15159v2)** | 2025-12-31 |  |
| **[Few-Shot-Based Modular Image-to-Video Adapter for Diffusion Models](https://arxiv.org/abs/2512.20000v2)** | 2025-12-31 | <details><summary>GitHu...</summary><p>GitHub page: https://github.com/yishaohan/MIVA</p></details> |
| **[DriveLaW:Unifying Planning and Video Generation in a Latent Driving World](https://arxiv.org/abs/2512.23421v2)** | 2025-12-31 | 17 pages, 7 figures |
| **[PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation](https://arxiv.org/abs/2512.24551v1)** | 2025-12-31 |  |
| **[Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation](https://arxiv.org/abs/2512.24271v1)** | 2025-12-30 | 18 pages |
| **[Infinity-RoPE: Action-Controllable Infinite Video Generation Emerges From Autoregressive Self-Rollout](https://arxiv.org/abs/2511.20649v2)** | 2025-12-30 | <details><summary>Proje...</summary><p>Project Page: https://infinity-rope.github.io/</p></details> |
| **[RainFusion2.0: Temporal-Spatial Awareness and Hardware-Efficient Block-wise Sparse Attention](https://arxiv.org/abs/2512.24086v1)** | 2025-12-30 |  |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Categorical Reparameterization with Denoising Diffusion models](https://arxiv.org/abs/2601.00781v1)** | 2026-01-02 | working paper |
| **[Clustering by Denoising: Latent plug-and-play diffusion for single-cell data](https://arxiv.org/abs/2510.22835v2)** | 2026-01-02 |  |
| **[Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion](https://arxiv.org/abs/2508.12094v3)** | 2026-01-02 |  |
| **[OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot](https://arxiv.org/abs/2510.06751v2)** | 2026-01-02 |  |
| **[FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535v1)** | 2026-01-02 |  |
| **[Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization](https://arxiv.org/abs/2601.00527v1)** | 2026-01-02 | <details><summary>Inter...</summary><p>International Conference on Software Engineering and Data Engineering : Springer Nature</p></details> |
| **[Mask-Conditioned Voxel Diffusion for Joint Geometry and Color Inpainting](https://arxiv.org/abs/2601.00368v1)** | 2026-01-01 | 10 pages, 9 figures |
| **[Joint Geometry-Appearance Human Reconstruction in a Unified Latent Space via Bridge Diffusion](https://arxiv.org/abs/2601.00328v1)** | 2026-01-01 |  |
| **[CrownGen: Patient-customized Crown Generation via Point Diffusion Model](https://arxiv.org/abs/2512.21890v2)** | 2026-01-01 |  |
| **[FP4DiT: Towards Effective Floating Point Quantization for Diffusion Transformers](https://arxiv.org/abs/2503.15465v3)** | 2025-12-31 | <details><summary>The c...</summary><p>The code is available at https://github.com/cccrrrccc/FP4DiT</p></details> |
| **[Compositional Diffusion with Guided search for Long-Horizon Planning](https://arxiv.org/abs/2601.00126v1)** | 2025-12-31 | 38 pages, 18 figures |
| **[Task-oriented Learnable Diffusion Timesteps for Universal Few-shot Learning of Dense Tasks](https://arxiv.org/abs/2512.23210v2)** | 2025-12-31 | <details><summary>Prema...</summary><p>Prematurely uploaded without mutual consent by all authors, with critical modifications necessary in the references</p></details> |
| **[GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction](https://arxiv.org/abs/2512.25073v1)** | 2025-12-31 | <details><summary>Proje...</summary><p>Project page: https://yichuanh.github.io/GaMO/</p></details> |
| **[Diffusion Language Models are Provably Optimal Parallel Samplers](https://arxiv.org/abs/2512.25014v1)** | 2025-12-31 |  |
| **[ProDM: Synthetic Reality-driven Property-aware Progressive Diffusion Model for Coronary Calcium Motion Correction in Non-gated Chest CT](https://arxiv.org/abs/2512.24948v1)** | 2025-12-31 | 21 pages, 8 figures |

