---
title: Latest 15 Papers - April 08, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[InterDyn: Controllable Interactive Dynamics with Video Diffusion Models](http://arxiv.org/abs/2412.11785v3)** | 2025-04-04 |  |
| **[VLIPP: Towards Physically Plausible Video Generation with Vision and Language Informed Physical Prior](http://arxiv.org/abs/2503.23368v3)** | 2025-04-04 | 18 pages, 11 figures |
| **[Audio-visual Controlled Video Diffusion with Masked Selective State Spaces Modeling for Natural Talking Head Generation](http://arxiv.org/abs/2504.02542v2)** | 2025-04-04 |  |
| **[Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency](http://arxiv.org/abs/2409.02634v3)** | 2025-04-04 | <details><summary>ICLR ...</summary><p>ICLR 2025 (Oral), Homepage: https://loopyavatar.github.io/</p></details> |
| **[Model Reveals What to Cache: Profiling-Based Feature Reuse for Video Diffusion Models](http://arxiv.org/abs/2504.03140v1)** | 2025-04-04 |  |
| **[MG-Gen: Single Image to Motion Graphics Generation with Layer Decomposition](http://arxiv.org/abs/2504.02361v2)** | 2025-04-04 |  |
| **[How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models](http://arxiv.org/abs/2504.03072v1)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted at ICLR 2024 (Oral)</p></details> |
| **[Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets](http://arxiv.org/abs/2504.02792v1)** | 2025-04-03 |  |
| **[Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model](http://arxiv.org/abs/2504.02764v1)** | 2025-04-03 | CVPR 2025 |
| **[Morpheus: Benchmarking Physical Reasoning of Video Generative Models with Real Physical Experiments](http://arxiv.org/abs/2504.02918v1)** | 2025-04-03 |  |
| **[VideoScene: Distilling Video Diffusion Model to Generate 3D Scenes in One Step](http://arxiv.org/abs/2504.01956v2)** | 2025-04-03 | <details><summary>Accep...</summary><p>Accepted by CVPR 2025; Project Page: https://hanyang-21.github.io/VideoScene</p></details> |
| **[ConMo: Controllable Motion Disentanglement and Recomposition for Zero-Shot Motion Transfer](http://arxiv.org/abs/2504.02451v1)** | 2025-04-03 |  |
| **[SkyReels-A2: Compose Anything in Video Diffusion Transformers](http://arxiv.org/abs/2504.02436v1)** | 2025-04-03 |  |
| **[OSV: One Step is Enough for High-Quality Image to Video Generation](http://arxiv.org/abs/2409.11367v2)** | 2025-04-03 |  |
| **[OmniCam: Unified Multimodal Video Generation via Camera Control](http://arxiv.org/abs/2504.02312v1)** | 2025-04-03 |  |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Enhancing Causal Effect Estimation with Diffusion-Generated Data](http://arxiv.org/abs/2504.03630v1)** | 2025-04-04 |  |
| **[Multimodal Diffusion Bridge with Attention-Based SAR Fusion for Satellite Image Cloud Removal](http://arxiv.org/abs/2504.03607v1)** | 2025-04-04 |  |
| **[Streaming Generation of Co-Speech Gestures via Accelerated Rolling Diffusion](http://arxiv.org/abs/2503.10488v2)** | 2025-04-04 |  |
| **[Diffusion Active Learning: Towards Data-Driven Experimental Design in Computed Tomography](http://arxiv.org/abs/2504.03491v1)** | 2025-04-04 |  |
| **[BUFF: Bayesian Uncertainty Guided Diffusion Probabilistic Model for Single Image Super-Resolution](http://arxiv.org/abs/2504.03490v1)** | 2025-04-04 | <details><summary>9 pag...</summary><p>9 pages, 5 figures, AAAI 2025</p></details> |
| **[Dynamic Importance in Diffusion U-Net for Enhanced Image Synthesis](http://arxiv.org/abs/2504.03471v1)** | 2025-04-04 | <details><summary>Accep...</summary><p>Accepted to ICME 2025. Appendix & Code: https://github.com/Hytidel/UNetReweighting</p></details> |
| **[D-Garment: Physics-Conditioned Latent Diffusion for Dynamic Garment Deformations](http://arxiv.org/abs/2504.03468v1)** | 2025-04-04 | 11 pages, 7 figures |
| **[Conditioning Diffusions Using Malliavin Calculus](http://arxiv.org/abs/2504.03461v1)** | 2025-04-04 |  |
| **[Edge-SD-SR: Low Latency and Parameter Efficient On-device Super-Resolution with Stable Diffusion via Bidirectional Conditioning](http://arxiv.org/abs/2412.06978v2)** | 2025-04-04 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025</p></details> |
| **[Training-Free Style and Content Transfer by Leveraging U-Net Skip Connections in Stable Diffusion](http://arxiv.org/abs/2501.14524v2)** | 2025-04-04 | <details><summary>Accep...</summary><p>Accepted to CVPR Workshop on AI for Creative Visual Content Generation Editing and Understanding 2025</p></details> |
| **[FaR: Enhancing Multi-Concept Text-to-Image Diffusion via Concept Fusion and Localized Refinement](http://arxiv.org/abs/2504.03292v1)** | 2025-04-04 |  |
| **[Audio-visual Controlled Video Diffusion with Masked Selective State Spaces Modeling for Natural Talking Head Generation](http://arxiv.org/abs/2504.02542v2)** | 2025-04-04 |  |
| **[ReviveDiff: A Universal Diffusion Model for Restoring Images in Adverse Weather Conditions](http://arxiv.org/abs/2409.18932v2)** | 2025-04-04 |  |
| **[FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation](http://arxiv.org/abs/2412.16915v2)** | 2025-04-04 | <details><summary>CVPR ...</summary><p>CVPR 2025, Homepage https://fadavatar.github.io/</p></details> |
| **[On the Connection Between Diffusion Models and Molecular Dynamics](http://arxiv.org/abs/2504.03187v1)** | 2025-04-04 | 13 pages, 5 figures |

