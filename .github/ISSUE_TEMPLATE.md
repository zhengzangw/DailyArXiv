---
title: Latest 15 Papers - September 17, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling](http://arxiv.org/abs/2509.12201v1)** | 2025-09-15 | <details><summary>https...</summary><p>https://yangzhou24.github.io/OmniWorld/</p></details> |
| **[Video Signature: In-generation Watermarking for Latent Video Diffusion Models](http://arxiv.org/abs/2506.00652v3)** | 2025-09-15 |  |
| **[AvatarSync: Rethinking Talking-Head Animation through Autoregressive Perspective](http://arxiv.org/abs/2509.12052v1)** | 2025-09-15 |  |
| **[MVQA-68K: A Multi-dimensional and Causally-annotated Dataset with Quality Interpretability for Video Assessment](http://arxiv.org/abs/2509.11589v1)** | 2025-09-15 |  |
| **[VideoAgent: Personalized Synthesis of Scientific Videos](http://arxiv.org/abs/2509.11253v1)** | 2025-09-14 |  |
| **[PanoLora: Bridging Perspective and Panoramic Video Generation with LoRA Adaptation](http://arxiv.org/abs/2509.11092v1)** | 2025-09-14 |  |
| **[Stable Part Diffusion 4D: Multi-View RGB and Kinematic Parts Video Generation](http://arxiv.org/abs/2509.10687v1)** | 2025-09-12 | <details><summary>Page:...</summary><p>Page: https://stablepartdiffusion4d.github.io/</p></details> |
| **[T2Bs: Text-to-Character Blendshapes via Video Generation](http://arxiv.org/abs/2509.10678v1)** | 2025-09-12 |  |
| **[Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](http://arxiv.org/abs/2509.10312v1)** | 2025-09-12 | <details><summary>11 pa...</summary><p>11 pages, 11 figures; Accepted by ACM MM2025; Mainly focus on feature caching for diffusion transformers acceleration</p></details> |
| **[Your Image is Secretly the Last Frame of a Pseudo Video](http://arxiv.org/abs/2410.20158v3)** | 2025-09-11 | <details><summary>Prese...</summary><p>Presented at the ICLR 2025 Workshop on Deep Generative Model in Machine Learning: Theory, Principle and Efficacy (DeLTa). 1-frame results for CIFAR10 in Table 2 corrected. Code released</p></details> |
| **[Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis](http://arxiv.org/abs/2509.09595v1)** | 2025-09-11 | <details><summary>Techn...</summary><p>Technical Report. Project Page: https://klingavatar.github.io/</p></details> |
| **[Improving Video Diffusion Transformer Training by Multi-Feature Fusion and Alignment from Self-Supervised Vision Encoders](http://arxiv.org/abs/2509.09547v1)** | 2025-09-11 | 17 pages, 14 figures |
| **[Zero-shot 3D-Aware Trajectory-Guided image-to-video generation via Test-Time Training](http://arxiv.org/abs/2509.06723v2)** | 2025-09-11 |  |
| **[S$^2$-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models](http://arxiv.org/abs/2508.12880v2)** | 2025-09-11 |  |
| **[RewardDance: Reward Scaling in Visual Generation](http://arxiv.org/abs/2509.08826v1)** | 2025-09-10 | <details><summary>Byted...</summary><p>Bytedance Seed Technical Report</p></details> |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence](http://arxiv.org/abs/2509.12203v1)** | 2025-09-15 |  |
| **[Video Signature: In-generation Watermarking for Latent Video Diffusion Models](http://arxiv.org/abs/2506.00652v3)** | 2025-09-15 |  |
| **[Robust Concept Erasure in Diffusion Models: A Theoretical Perspective on Security and Robustness](http://arxiv.org/abs/2509.12024v1)** | 2025-09-15 | Camera ready version |
| **[Optimization for Massive 3D-RIS Deployment: A Generative Diffusion Model-Based Approach](http://arxiv.org/abs/2509.11969v1)** | 2025-09-15 |  |
| **[Adaptive least-squares space-time finite element methods for convection-diffusion problems](http://arxiv.org/abs/2509.11955v1)** | 2025-09-15 |  |
| **[VH-Diffuser: Variable Horizon Diffusion Planner for Time-Aware Goal-Conditioned Trajectory Planning](http://arxiv.org/abs/2509.11930v1)** | 2025-09-15 |  |
| **[Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer](http://arxiv.org/abs/2509.11865v1)** | 2025-09-15 | 8 pages, 4 figures |
| **[SCP-Diff: Spatial-Categorical Joint Prior for Diffusion Based Semantic Image Synthesis](http://arxiv.org/abs/2403.09638v3)** | 2025-09-15 | <details><summary>Proje...</summary><p>Project Page: https://air-discover.github.io/SCP-Diff/</p></details> |
| **[Comparing Conditional Diffusion Models for Synthesizing Contrast-Enhanced Breast MRI from Pre-Contrast Images](http://arxiv.org/abs/2508.13776v2)** | 2025-09-15 | <details><summary>13 pa...</summary><p>13 pages, 5 figures, submitted and accepted to MICCAI Deepbreath workshop 2025</p></details> |
| **[DRAG: Data Reconstruction Attack using Guided Diffusion](http://arxiv.org/abs/2509.11724v1)** | 2025-09-15 | ICML 2025 |
| **[DTGen: Generative Diffusion-Based Few-Shot Data Augmentation for Fine-Grained Dirty Tableware Recognition](http://arxiv.org/abs/2509.11661v1)** | 2025-09-15 |  |
| **[IS-Diff: Improving Diffusion-Based Inpainting with Better Initial Seed](http://arxiv.org/abs/2509.11638v1)** | 2025-09-15 |  |
| **[SpeCa: Accelerating Diffusion Transformers with Speculative Feature Caching](http://arxiv.org/abs/2509.11628v1)** | 2025-09-15 | <details><summary>15 pa...</summary><p>15 pages, 9 figures, ACM Multimedia 2025</p></details> |
| **[Inference-stage Adaptation-projection Strategy Adapts Diffusion Policy to Cross-manipulators Scenarios](http://arxiv.org/abs/2509.11621v1)** | 2025-09-15 | <details><summary>2025 ...</summary><p>2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works</p></details> |
| **[OSDM-MReg: Multimodal Image Registration based One Step Diffusion Model](http://arxiv.org/abs/2504.06027v2)** | 2025-09-15 | <details><summary>This ...</summary><p>This version updates our previous submission. After rerunning the experiments, we found that the proposed high-frequency perceptual loss did not improve the overall performance of the model. Therefore, we removed this component, revised the corresponding ablation studies, and updated the contributions accordingly. This work has been submitted to the IEEE for possible publication</p></details> |

