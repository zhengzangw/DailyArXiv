---
title: Latest 15 Papers - December 10, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Video Generation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation](https://arxiv.org/abs/2512.07831v1)** | 2025-12-08 | <details><summary>Proje...</summary><p>Project Website https://jackailab.github.io/Projects/UnityVideo</p></details> |
| **[TV2TV: A Unified Framework for Interleaved Language and Video Generation](https://arxiv.org/abs/2512.05103v2)** | 2025-12-08 |  |
| **[WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling](https://arxiv.org/abs/2512.07821v1)** | 2025-12-08 |  |
| **[OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory](https://arxiv.org/abs/2512.07802v1)** | 2025-12-08 | <details><summary>Proje...</summary><p>Project Page: https://zhaochongan.github.io/projects/OneStory</p></details> |
| **[ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation](https://arxiv.org/abs/2512.07720v1)** | 2025-12-08 |  |
| **[LAMP: Language-Assisted Motion Planning for Controllable Video Generation](https://arxiv.org/abs/2512.03619v2)** | 2025-12-08 | <details><summary>Proje...</summary><p>Project Page: https://cyberiada.github.io/LAMP/</p></details> |
| **[Communication-Efficient Serving for Video Diffusion Models with Latent Parallelism](https://arxiv.org/abs/2512.07350v1)** | 2025-12-08 | 19 pages |
| **[ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation](https://arxiv.org/abs/2512.07328v1)** | 2025-12-08 |  |
| **[Unified Camera Positional Encoding for Controlled Video Generation](https://arxiv.org/abs/2512.07237v1)** | 2025-12-08 | <details><summary>Code:...</summary><p>Code: https://github.com/chengzhag/UCPE</p></details> |
| **[Coefficients-Preserving Sampling for Reinforcement Learning with Flow Matching](https://arxiv.org/abs/2509.05952v4)** | 2025-12-08 | work in progress |
| **[MotionStream: Real-Time Video Generation with Interactive Motion Controls](https://arxiv.org/abs/2511.01266v2)** | 2025-12-08 | <details><summary>Proje...</summary><p>Project webpage: https://joonghyuk.com/motionstream-web/</p></details> |
| **[VideoVLA: Video Generators Can Be Generalizable Robot Manipulators](https://arxiv.org/abs/2512.06963v1)** | 2025-12-07 | <details><summary>Proje...</summary><p>Project page: https://videovla-nips2025.github.io</p></details> |
| **[Scaling Zero-Shot Reference-to-Video Generation](https://arxiv.org/abs/2512.06905v1)** | 2025-12-07 | <details><summary>Websi...</summary><p>Website: https://franciszzj.github.io/Saber/</p></details> |
| **[EVCtrl: Efficient Control Adapter for Visual Generation](https://arxiv.org/abs/2508.10963v2)** | 2025-12-07 |  |
| **[NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation](https://arxiv.org/abs/2512.05106v2)** | 2025-12-07 |  |

## Diffusion
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Diffusion Models for Image Restoration and Enhancement: A Comprehensive Survey](https://arxiv.org/abs/2308.09388v3)** | 2025-12-08 | <details><summary>Accep...</summary><p>Accepted by IJCV 2025</p></details> |
| **[DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving](https://arxiv.org/abs/2512.07745v1)** | 2025-12-08 |  |
| **[Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks](https://arxiv.org/abs/2512.07697v1)** | 2025-12-08 |  |
| **[Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer](https://arxiv.org/abs/2511.22699v3)** | 2025-12-08 |  |
| **[Optimization-Guided Diffusion for Interactive Scene Generation](https://arxiv.org/abs/2512.07661v1)** | 2025-12-08 |  |
| **[SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots](https://arxiv.org/abs/2512.02851v3)** | 2025-12-08 | <details><summary>This ...</summary><p>This work has been submitted for publication and is currently under review</p></details> |
| **[Training-Free Diffusion Priors for Text-to-Image Generation via Optimization-based Visual Inversion](https://arxiv.org/abs/2511.20821v2)** | 2025-12-08 | <details><summary>11 pa...</summary><p>11 pages, 7 figures, technical report (preprint)</p></details> |
| **[MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer](https://arxiv.org/abs/2512.07500v1)** | 2025-12-08 |  |
| **[RealD$^2$iff: Bridging Real-World Gap in Robot Manipulation via Depth Diffusion](https://arxiv.org/abs/2511.22505v2)** | 2025-12-08 | <details><summary>We ar...</summary><p>We are the author team of the paper "RealD$^2$iff: Bridging Real-World Gap in Robot Manipulation via Depth Diffusion". After self-examination, our team discovered inappropriate wording in the citation of related work, the introduction, and the contribution statement, which may affect the contribution of other related works. Therefore, we have decided to revise the paper and request its withdrawal</p></details> |
| **[Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance](https://arxiv.org/abs/2512.07480v1)** | 2025-12-08 |  |
| **[InterAgent: Physics-based Multi-agent Command Execution via Diffusion on Interaction Graphs](https://arxiv.org/abs/2512.07410v1)** | 2025-12-08 | <details><summary>Proje...</summary><p>Project page: https://binlee26.github.io/InterAgent-Page</p></details> |
| **[Modeling diffusion in networks with communities: a multitype branching process approach](https://arxiv.org/abs/2408.04456v2)** | 2025-12-08 |  |
| **[Communication-Efficient Serving for Video Diffusion Models with Latent Parallelism](https://arxiv.org/abs/2512.07350v1)** | 2025-12-08 | 19 pages |
| **[Debiasing Diffusion Priors via 3D Attention for Consistent Gaussian Splatting](https://arxiv.org/abs/2512.07345v1)** | 2025-12-08 | <details><summary>15 pa...</summary><p>15 pages, 8 figures, 5 tables, 2 algorithms, Accepted by AAAI 2026</p></details> |
| **[ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation](https://arxiv.org/abs/2512.07328v1)** | 2025-12-08 |  |

